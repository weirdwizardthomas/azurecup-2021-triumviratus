{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikI_S6_21HdE"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import zipfile\n",
    "from struct import unpack\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrMIic6c6FU2"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xr2s5Wj8bJQ"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('kaggle'):\n",
    "  os.mkdir('kaggle')\n",
    "# TODO setup kaggle credentials in an external, non-comitted file\n",
    "with open('kaggle/kaggle.json', 'w') as file:\n",
    "  file.write('{\"username\" : \"\",\"key\" : \"\"}')\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"kaggle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIVqgr6i71mx",
    "outputId": "53f76a88-b0d3-4020-fb4d-e5597886e8e1"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d maysee/mushrooms-classification-common-genuss-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TemjHK1i78b3"
   },
   "outputs": [],
   "source": [
    "# name of the zip file you want to unzip\n",
    "local_zip = 'mushrooms-classification-common-genuss-images.zip'\n",
    "# opening a file with mode parameter 'r' : read existing file\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "# extract all contents of the zip file\n",
    "zip_ref.extractall('')\n",
    "# close the file\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "io_MzHEjiL4W"
   },
   "outputs": [],
   "source": [
    "!rm mushrooms-classification-common-genuss-images.zip\n",
    "!rm -rf mushrooms\n",
    "!rm -rf sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ys1m2VhswADk",
    "outputId": "b7e03d99-622b-49ab-a45d-c31b2dd8ad89"
   },
   "outputs": [],
   "source": [
    "marker_mapping = {\n",
    "    0xffd8 : \"Start of Image\",\n",
    "    0xffe0 : \"Application Default Header\",\n",
    "    0xffdb : \"Quantization Table\",\n",
    "    0xffc0 : \"Start of Frame\",\n",
    "    0xffc4 : \"Define Huffman Table\",\n",
    "    0xffda : \"Start of Scan\",\n",
    "    0xffd9 : \"End of Image\"\n",
    "}\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data) == 0:\n",
    "                break        \n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(glob.glob('Mushrooms/**/*')):\n",
    "  image = JPEG(img)\n",
    "  try:\n",
    "    image.decode()   \n",
    "  except:\n",
    "    bads.append(img)\n",
    "\n",
    "for name in tqdm(bads):\n",
    "  print('[X]',name)\n",
    "  os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDgMbdHHA2xZ"
   },
   "outputs": [],
   "source": [
    "shrooms = glob.glob('Mushrooms/**/*')\n",
    "\n",
    "train, test = train_test_split(shrooms, test_size = 0.2)\n",
    "\n",
    "names = set()\n",
    "for file in tqdm(shrooms):\n",
    "  name = file.replace('Mushrooms/','').split('/')[0]\n",
    "  names.add(name)\n",
    "\n",
    "for name in tqdm(names):\n",
    "  for set_name in ('train','test'):\n",
    "    os.makedirs('{}/{}'.format(set_name,name), exist_ok = True)\n",
    "\n",
    "for source in tqdm(train):\n",
    "  target = source.replace('Mushrooms', 'train')\n",
    "  shutil.copy(source,target)\n",
    "\n",
    "for source in tqdm(test):\n",
    "  target = source.replace('Mushrooms', 'test')\n",
    "  shutil.copy(source,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQ5RMT5lAGbE",
    "outputId": "f4614e31-d85b-4e74-fdcb-a5b58be10ab0"
   },
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    'labels'            : 'inferred',\n",
    "    'label_mode'        : 'categorical',\n",
    "    'class_names'       : ['Russula', 'Entoloma', 'Amanita', 'Lactarius', 'Cortinarius', 'Hygrocybe', 'Agaricus', 'Suillus', 'Boletus'],\n",
    "    'color_mode'        : 'grayscale',\n",
    "    'batch_size'        : 64,\n",
    "    'shuffle'           : True,\n",
    "    'seed'              : 42,\n",
    "    'validation_split'  : 0.25,\n",
    "    'image_size'        : (256, 256),\n",
    "    'interpolation'     : 'bilinear',\n",
    "    'follow_links'      : False\n",
    "    }\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels            = dataset_config['labels'],\n",
    "    label_mode        = dataset_config['label_mode'],\n",
    "    class_names       = dataset_config['class_names'],\n",
    "    color_mode        = dataset_config['color_mode'],\n",
    "    batch_size        = dataset_config['batch_size'],\n",
    "    image_size        = dataset_config['image_size'],\n",
    "    shuffle           = dataset_config['shuffle'],\n",
    "    seed              = dataset_config['seed'],\n",
    "    validation_split  = dataset_config['validation_split'],\n",
    "    subset            = 'training',\n",
    "    interpolation     = dataset_config['interpolation'],\n",
    "    follow_links      = dataset_config['follow_links'],\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    'test',\n",
    "    labels            = dataset_config['labels'],\n",
    "    label_mode        = dataset_config['label_mode'],\n",
    "    class_names       = dataset_config['class_names'],\n",
    "    color_mode        = dataset_config['color_mode'],\n",
    "    batch_size        = dataset_config['batch_size'],\n",
    "    image_size        = dataset_config['image_size'],\n",
    "    shuffle           = dataset_config['shuffle'],\n",
    "    seed              = dataset_config['seed'],\n",
    "    subset            = None,\n",
    "    interpolation     = dataset_config['interpolation'],\n",
    "    follow_links      = dataset_config['follow_links'],\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels            = dataset_config['labels'],\n",
    "    label_mode        = dataset_config['label_mode'],\n",
    "    class_names       = dataset_config['class_names'],\n",
    "    color_mode        = dataset_config['color_mode'],\n",
    "    batch_size        = dataset_config['batch_size'],\n",
    "    image_size        = dataset_config['image_size'],\n",
    "    shuffle           = dataset_config['shuffle'],\n",
    "    seed              = dataset_config['seed'],\n",
    "    validation_split  = dataset_config['validation_split'],\n",
    "    subset            = 'validation',\n",
    "    interpolation     = dataset_config['interpolation'],\n",
    "    follow_links      = dataset_config['follow_links'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuIRGH_L5Bup"
   },
   "outputs": [],
   "source": [
    "# https://blogs.oracle.com/meena/simple-neural-network-model-using-keras-and-grid-search-hyperparameterstuning\n",
    "activation = ['relu','tanh','sigmoid','linear']\n",
    "momentum = [0.0, 0.2, 0.5, 0.6, 0.8, 0.9]\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "weight_constraint = [1, 2, 3, 4, 5]\n",
    "epochs = [1, 10, 20, 25, 50, 100, 150]\n",
    "batch_size = [8, 16, 32, 64, 128]\n",
    "param_grid = {\n",
    "    'activation'        : activation,\n",
    "    'momentum'          : momentum,\n",
    "    'learn_rate'        : learn_rate,\n",
    "    'weight_constraint' : weight_constraint,\n",
    "    'epochs'            : epochs,\n",
    "    'batch_size'        : batch_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c26aQGEix_qu"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(dataset_config['image_size'][0], dataset_config['image_size'][1], 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, kernel_constraint=maxnorm(3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "epochs = 50\n",
    "optimizer = 'Adam'\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMFN6sHr5C8n",
    "outputId": "9b48475f-2842-4b73-b872-7ef9d43acce4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEoYpTNryB0B",
    "outputId": "b0d47c4a-550a-4655-bb36-50c90c01a70c"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset, validation_data = val_dataset, epochs = epochs, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8GLTC3OyDP7",
    "outputId": "68593c3e-5f9d-4393-aefd-ca02f754f560"
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(test_dataset, verbose = 0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of FungusAmongUs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
